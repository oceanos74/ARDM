{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_replace(s, r, t, forward=True, backward=False):\n",
    "    def clean_replace_single(s, r, t, forward, backward, sidx=0):\n",
    "        idx = s[sidx:].lower().find(r.lower())\n",
    "        if idx == -1:\n",
    "            return s, -1\n",
    "        idx += sidx\n",
    "        idx_r = idx + len(r)\n",
    "        if backward:\n",
    "            while idx > 0 and s[idx - 1]:\n",
    "                idx -= 1\n",
    "        elif idx > 0 and s[idx - 1] != ' ':\n",
    "            return s, -1\n",
    "\n",
    "        if forward:\n",
    "            while idx_r < len(s) and (s[idx_r].isalpha() or s[idx_r].isdigit()):\n",
    "                idx_r += 1\n",
    "        elif idx_r != len(s) and (s[idx_r].isalpha() or s[idx_r].isdigit()):\n",
    "            return s, -1\n",
    "        return s[:idx] + t + s[idx_r:], idx_r\n",
    "\n",
    "    sidx = 0\n",
    "    while sidx != -1:\n",
    "        s, sidx = clean_replace_single(s, r, t, forward, backward, sidx)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_key_map(db_data):\n",
    "    requestable_keys = ['address', 'name', 'phone', 'postcode', 'food', 'area', 'pricerange']\n",
    "    value_key = {}\n",
    "    for db_entry in db_data:\n",
    "        for k, v in db_entry.items():\n",
    "            if k in requestable_keys:\n",
    "                value_key[v] = k\n",
    "    return value_key\n",
    "\n",
    "def db_search(db, constraints):\n",
    "    \"\"\"when doing matching, remember to lower case\"\"\"\n",
    "    match_results = []\n",
    "    for entry in db:\n",
    "        entry_values = ' '.join(entry.values()).lower()\n",
    "        match = True\n",
    "        for c in constraints:\n",
    "            if c.lower() not in entry_values:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            match_results.append(entry)\n",
    "    return match_results\n",
    "\n",
    "def replace_entity(response, vk_map, constraint):\n",
    "    response = re.sub('[cC][., ]*[bB][., ]*\\d[., ]*\\d[., ]*\\w[., ]*\\w', '<postcode_SLOT>', response)\n",
    "    response = re.sub('\\d{5}\\s?\\d{6}', '<phone_SLOT>', response)\n",
    "    constraint_str = ' '.join(constraint)\n",
    "    for v, k in sorted(vk_map.items(), key=lambda x: -len(x[0])):\n",
    "        start_idx = response.lower().find(v.lower())\n",
    "        if start_idx == -1 \\\n",
    "                or (start_idx != 0 and response[start_idx - 1] != ' ') \\\n",
    "                or (v in constraint_str):\n",
    "            continue\n",
    "        if k not in ['name', 'address']:\n",
    "            response = clean_replace(response, v, '<' + k + '_SLOT>', forward=True, backward=False)\n",
    "        else:\n",
    "            response = clean_replace(response, v, '<' + k + '_SLOT>', forward=False, backward=False)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../CamRest676/CamRest676.json\", \"r\") as f:\n",
    "    raw_data = json.loads(f.read())\n",
    "    \n",
    "# read database\n",
    "with open(\"../CamRest676/CamRestDB.json\", \"r\") as f:\n",
    "    db_data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk_map = value_key_map(db_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "for dial_id, dial in enumerate(raw_data):\n",
    "    \n",
    "    one_dialog = []\n",
    "    \n",
    "    for turn in dial['dial']:\n",
    "        turn_num = turn['turn']\n",
    "        constraint = []\n",
    "        requested = []\n",
    "        \n",
    "        for slot in turn['usr']['slu']:\n",
    "            if slot['act'] == 'inform':\n",
    "                s = slot['slots'][0][1]\n",
    "                if s not in ['dontcare', 'none']:\n",
    "                    constraint.extend(word_tokenize(s))\n",
    "            else:\n",
    "                requested.extend(word_tokenize(slot['slots'][0][1]))\n",
    "        \n",
    "        degree = len(db_search(db_data, constraint))\n",
    "        if degree > 6:\n",
    "            degree = 6\n",
    "        \n",
    "        constraint.insert(0, '[inform]')\n",
    "        requested.insert(0, '[request]')\n",
    "        \n",
    "        user = turn['usr']['transcript']\n",
    "        real_response = turn['sys']['sent']\n",
    "        replaced_response = replace_entity(real_response, vk_map, constraint)\n",
    "        \n",
    "        one_dialog.append({\n",
    "            'dial_id': dial_id,\n",
    "            'turn_num': turn_num,\n",
    "            'user': user,\n",
    "            'real_response': real_response,\n",
    "            'replaced_response': replaced_response,\n",
    "            'degree': degree,\n",
    "            'bspan_inform': constraint,\n",
    "            'bspan_request': requested,\n",
    "        })\n",
    "    \n",
    "    all_data.append(one_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(all_data))\n",
    "# np.random.shuffle(indices)\n",
    "train_data = indices[:408]\n",
    "val_data = indices[408:544]\n",
    "test_data = indices[544:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [all_data[idx] for idx in train_data]\n",
    "val_data = [all_data[idx] for idx in val_data]\n",
    "test_data = [all_data[idx] for idx in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data, \"train_data.pkl\")\n",
    "torch.save(val_data, \"val_data.pkl\")\n",
    "torch.save(test_data, \"test_data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
